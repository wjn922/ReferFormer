## Ref-Youtube-VOS

### Model Zoo

To evaluate the results, please upload the zip file to the [competition server](https://competitions.codalab.org/competitions/29139#participate-submit_results).

| Backbone| J&F | CFBI J&F  | Pretrain | Model | Submission | CFBI Submission | 
| :----: | :----: | :----: | :----: | :----: | :----: | :----: | 
| ResNet-50 | 55.6 | 59.4 | [weight](https://drive.google.com/file/d/1zFBTmWhHQn_QxN84hpT-fA0C5TzZUAZK/view?usp=sharing) | [model](https://drive.google.com/file/d/1TBykzTRiOEbpM2YEYnDICyqjwkvlD2cR/view?usp=sharing) | [link](https://drive.google.com/file/d/10jlaCgIA9D91kb7d5_En-iUusoKU02mh/view?usp=sharing) | [link](https://drive.google.com/file/d/1H3m6jAXZNXIxEnIMpkvb_iYb62v2hAn2/view?usp=sharing) |
| ResNet-101 | 57.3 | 60.3 | [weight](https://drive.google.com/file/d/1FKIdXM9UEHSn93Xhbqi2hYBktDRMBsLr/view?usp=sharing) | [model](https://drive.google.com/file/d/1QJU8HC8xk_3gMcj-Yi4vkUHaeHeP8n82/view?usp=sharing) | [link](https://drive.google.com/file/d/15DZ0QXCdFmg0GHM0CgMAH20ZVbuCaBEW/view?usp=sharing) | [link](https://drive.google.com/file/d/1FCZcRqoPXdTnoODQxre7pGOIBCuWNv_v/view?usp=sharing) |
| Swin-T | 58.7 | 61.2 | [weight](https://drive.google.com/file/d/1TcGsseTVftkpdw_glFOwG-Zvg3NMEPuw/view?usp=sharing) | [model](https://drive.google.com/file/d/1AOHK6Qp8T0rUzgHT9twvWn4oGLS5MnuS/view?usp=sharing) | [link](https://drive.google.com/file/d/1kvzSLtDQTZjPLQ-9YKy8YmhN_JKheSmJ/view?usp=sharing) | [link](https://drive.google.com/file/d/1y3eegr7aB2R80L8WfRhcD-UfS3KF3U-5/view?usp=sharing) |
| Swin-L | 62.4 | 63.3 | [weight](https://drive.google.com/file/d/1pM7mBgvHtI_XNbfkX5eKT4jsUaLL3Qa4/view?usp=sharing) | [model](https://drive.google.com/file/d/103N96BbQnT9P57aGx7TCsZVyGr3ejFdl/view?usp=sharing) | [link](https://drive.google.com/file/d/1o18UzDUCy-NtoIGMxsD9VGu7y3H5HADk/view?usp=sharing) | [link](https://drive.google.com/file/d/1MnIibGGh9IhQ00qiqU7VCTH9CWE1ron3/view?usp=sharing) |
| Video-Swin-T* | 56.0 | - | - | [model](https://drive.google.com/file/d/14X_YysCXv13LzLoWy9ViIn623KQ-ol51/view?usp=sharing) | [link](https://drive.google.com/file/d/1TuADkEDibY8gW3On0K8fzi8-9JPnio0W/view?usp=sharing) | - |
| Video-Swin-T | 59.4 | - | [weight](https://drive.google.com/file/d/1qaEuOocLOZoj89unhZP3oN708ofmqopS/view?usp=sharing) | [model](https://drive.google.com/file/d/1vkG8nyUue9XOnScUMKo__khhxvuJP9R6/view?usp=sharing) | [link](https://drive.google.com/file/d/1LlZ00AhWzzW5uDyBy21qvZTJ2gnbC2r4/view?usp=sharing) | - |
| Video-Swin-S | 60.1 | - | [weight](https://drive.google.com/file/d/1SHzlzxE-KQeoGoYucdnPZtw_uz2ymgxn/view?usp=sharing) | [model](https://drive.google.com/file/d/1R0C5hYck6OwKko9tXOpIQ02SuE4mb1xj/view?usp=sharing) | [link](https://drive.google.com/file/d/1gcN_oD3-qh5wSuqUeDtwQpuwaWdJ9A6k/view?usp=sharing) | - |
| Video-Swin-B | 62.9 | - |[weight](https://drive.google.com/file/d/1gbyknvuOiKpxK1kljxFnt1k5Jxp3R1jv/view?usp=sharing)  | [model](https://drive.google.com/file/d/1_dS8hyZJFdijvsDVmoVcHjWhRE6sAXvS/view?usp=sharing) | [link](https://drive.google.com/file/d/1H8r3DgKeVuoh4egFeE9jS7ytknbD_xSb/view?usp=sharing) | - |

\* indicates the model is trained from scratch.


Joint training with Ref-COCO/+/g datasets.
| Backbone| J&F | J | F | Model | Submission | 
| :----: | :----: | :----: | :----: | :----: | :----: |
| ResNet-50 | 58.7 | 57.4 | 60.1 | [model](https://drive.google.com/file/d/1GAzI9zLEQKxp5KQHu1FOuqlw5PwAhMey/view?usp=sharing) | [link](https://drive.google.com/file/d/1cELD6A7zs0POgIW5_xZIX-pCDdmmn5WP/view?usp=sharing) |
| ResNet-101 | 59.3 | 58.1 | 60.4 | [model](https://drive.google.com/file/d/1R4PThhYGqaanm3h46gygQ6strHVJBpn5/view?usp=sharing) | [link](https://drive.google.com/file/d/1S1uxYbM_dLddtZRKxfMdXZhKpEv1hkZ3/view?usp=sharing) |
| Swin-L | 64.2 | 62.3 | 66.2 | [model](https://drive.google.com/file/d/1_nGi5JjlRcOUI8kXXduOE5iv0apnSXgR/view?usp=sharing) | [link](https://drive.google.com/file/d/1SL1JdM0zutNkef7x_9lUr0hbn25dMMZV/view?usp=sharing) |
| Video-Swin-T | 62.6 | 59.9 | 63.3 | [model](https://drive.google.com/file/d/1gPVVdAuX_0-H2McPPJYX6HldGQtekD8b/view?usp=sharing) | [link](https://drive.google.com/file/d/1d-XVhMlTOZDQJC_4a9rKzan5rMdxO1yl/view?usp=sharing) |
| Video-Swin-S | 63.3 | 61.4 | 65.2 | [model](https://drive.google.com/file/d/1zm9URDfL19xi5LN9vCM2c58-W-A5RCz_/view?usp=sharing) | [link](https://drive.google.com/file/d/10Qz1jpNVrHaXYxXs4AVH_2Zqut2d0WAD/view?usp=sharing) |
| Video-Swin-B | 64.9 | 62.8 | 67.0 | [model](https://drive.google.com/file/d/183AJLTtzwL15r-hhG9hUFrK5tfq37BH1/view?usp=sharing) | [link](https://drive.google.com/file/d/1CKCgoTbg6PwVZRzQ80CMiieq9NEtPNWD/view?usp=sharing) |

### Inference & Evaluation


First, inference using the trained model.

```
python3 inference_ytvos.py --with_box_refine --binary --freeze_text_encoder --output_dir=[/path/to/output_dir] --resume=[/path/to/model_weight] --backbone [backbone] 
```

```
python3 inference_ytvos.py --with_box_refine --binary --freeze_text_encoder --output_dir=ytvos_dirs/swin_tiny --resume=ytvos_swin_tiny.pth --backbone swin_t_p4w7
```

If you want to visualize the predited masks, you may add `--visualize` to the above command.

Then, enter the `output_dir`, rename the folder `valid` as `Annotations`. Use the following command to zip the folder:

```
zip -q -r submission.zip Annotations
```

To evaluate the results, please upload the zip file to the [competition server](https://competitions.codalab.org/competitions/29139#participate-submit_results).

### Training


- Finetune 

The following command includes the training and inference stages.

```
./scripts/dist_train_test_ytvos.sh [/path/to/output_dir] [/path/to/pretrained_weight] --backbone [backbone] 
```

For example, training the Video-Swin-Tiny model, run the following command:

```
./scripts/dist_train_test_ytvos.sh ytvos_dirs/video_swin_tiny pretrained_weights/video_swin_tiny_pretrained.pth --backbone video_swin_t_p4w7 
```

- Train from scratch

The following command includes the training and inference stages.

```
./scripts/dist_train_test_ytvos_scratch.sh [/path/to/output_dir] --backbone [backbone] --backbone_pretrained [/path/to/backbone_pretrained_weight] [other args]
```

For example, training the Video-Swin-Tiny model, run the following command:

```
./scripts/dist_train_test_ytvos.sh ytvos_dirs/video_swin_tiny_scratch --backbone video_swin_t_p4w7 --backbone_pretrained video_swin_pretrained/swin_tiny_patch244_window877_kinetics400_1k.pth
```
